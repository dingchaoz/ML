{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import decimal\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.nonparametric import smoothers_lowess\n",
    "from pandas import Series, DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#data = pd.read_csv('data', parse_dates=[[0,1]], infer_datetime_format=True)\n",
    "df = pd.read_csv(\"training.csv\", infer_datetime_format=True,low_memory=False)\n",
    "\n",
    "columnNames = ['int_rate','id_loan','id_borrower','loan_amt','funded_amt','funded_amt_inv',\n",
    "              'term','grade','subgrade','emp_title','emp_length','home_ownership','annual_inc',\n",
    "               'verification_status','issue_d','purpose','loan_cat','loan_title','zip_code',\n",
    "               'state','dti','delinq_2yrs','earliest_cr_line','inq_last_6mths','mths_since_last_deliq',\n",
    "               'mths_since_last_record','num_opencr_line','num_der_rec','revol_bal','revol_util',\n",
    "               'total_cr_line','init_list_status']\n",
    "\n",
    "df.columns = columnNames\n",
    "\n",
    "# Pandas can not store NaN in int type column, thus had remove all NaNs from them as well\n",
    "for col in ('loan_amt','funded_amt','funded_amt_inv', 'term'):\n",
    "    df = df[pd.notnull(df[col])]\n",
    "    \n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "D = decimal.Decimal\n",
    "# Pandas can not store NaN in int type column, thus had remove all NaNs\n",
    "for col in ('loan_amt','funded_amt','funded_amt_inv','term'):\n",
    "    df[col] = df[col].str.replace(r'[^-+\\d.]', '').astype(D)\n",
    "    df[col] = df[col].astype('int')\n",
    "    \n",
    "#  Convert columns having % from obj(string type) to float and divide by 100    \n",
    "df['int_rate'] = df['int_rate'].str.replace('%','').astype('float')/100\n",
    "\n",
    "# Remove the rows where int_rate is missing\n",
    "df = df[pd.notnull(df['int_rate'])]\n",
    "# Reset index, this is critical\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.drop(['id_loan','id_borrower'],1, inplace=True)\n",
    "\n",
    "from datetime import datetime\n",
    "# Read the column in the correct format\n",
    "temp = pd.to_datetime(df['issue_d'],format = '%b-%d')\n",
    "\n",
    "date_format = \"%m/%d/%Y\"\n",
    "dttoday = datetime.strptime('1/1/1900', date_format)\n",
    "\n",
    "d = np.zeros(len(temp))\n",
    "for i in range(len(temp)):\n",
    "    try:\n",
    "        d[i] = ((np.timedelta64(temp[i] - pd.Timestamp(dttoday),'D').astype(int))/365)\n",
    "        #break\n",
    "    except:\n",
    "        d[i] = ((np.timedelta64(temp[i] - pd.Timestamp(dttoday),'M').astype(int))/12)\n",
    "\n",
    "df['issue_d'] = d\n",
    "\n",
    "# Remove the rows where annual income claim is larger than 1 million\n",
    "df = df[df['annual_inc'] <= 1000000]\n",
    "# Reset index, this is critical\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.drop(['emp_title'],1, inplace=True)\n",
    "\n",
    "df.replace('n/a', np.nan,inplace=True)\n",
    "df.emp_length.fillna(value=0,inplace=True)\n",
    "df['emp_length'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "df['emp_length'] = df['emp_length'].astype(int)\n",
    "\n",
    "df.drop(['purpose'],1, inplace=True)\n",
    "df.drop(['loan_title'],1, inplace=True)\n",
    "df.drop(['zip_code'],1, inplace=True)\n",
    "\n",
    "from datetime import datetime\n",
    "# Read the column in the correct format\n",
    "t = pd.to_datetime(df['earliest_cr_line'],format = '%b-%y')\n",
    "\n",
    "date_format = \"%m/%d/%Y\"\n",
    "dttoday = datetime.strptime('1/1/2017', date_format)\n",
    "\n",
    "d = np.zeros(len(t))\n",
    "for i in range(len(t)):\n",
    "    try:\n",
    "        d[i] = ((np.timedelta64(t[i] - pd.Timestamp(dttoday),'D').astype(int))/-365)\n",
    "        #break\n",
    "    except:\n",
    "        d[i] = ((np.timedelta64(t[i] - pd.Timestamp(dttoday),'M').astype(int))/-12)\n",
    "\n",
    "d[d<0] = d[d<0] + 100\n",
    "\n",
    "df['earliest_cr_line'] = d\n",
    "\n",
    "df.revol_util = pd.Series(df.revol_util).str.replace('%', '').astype(float)\n",
    "\n",
    "df.drop(['funded_amt','funded_amt_inv','mths_since_last_deliq', 'total_cr_line'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import ensemble\n",
    "# from sklearn import datasets\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# y = df2.int_rate.values\n",
    "# df2.drop('int_rate',axis = 1, inplace=True)\n",
    "\n",
    "# X, y = shuffle(df2.values, y, random_state=30)\n",
    "# #X = X.astype(np.float64)\n",
    "\n",
    "# offset = int(X.shape[0] * 0.75)\n",
    "# X_train, y_train = X[:offset], y[:offset]\n",
    "# X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# param_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "#               'max_depth': [4, 6],\n",
    "#               'min_samples_leaf': [3, 5, 9, 17],\n",
    "#               'max_features': [1.0, 0.3, 0.1]\n",
    "#               }\n",
    "param_grid = {'learning_rate': [0.1],\n",
    "              'max_depth': [4],\n",
    "              'min_samples_leaf': [3],\n",
    "              'max_features': [1.0],\n",
    "              }\n",
    "\n",
    "est = GridSearchCV(ensemble.GradientBoostingRegressor(n_estimators=100),\n",
    "                   param_grid, n_jobs=4, refit=True)\n",
    "\n",
    "# Create an acceptable formula for our machine learning algorithms\n",
    "#formula_ml = 'int_rate ~ C(grade) + C(subgrade) + annual_inc + dti + mths_since_last_record + C(state)'\n",
    "\n",
    "formula_ml = 'int_rate ~ loan_amt '\n",
    "for i in range(2,len(df.columns)):\n",
    "    \n",
    "    if str(df.dtypes[i]) == 'object': \n",
    "        formula_ml = formula_ml + ' + ' + 'C(' + df.columns[i] + ')'\n",
    "    elif (str(df.dtypes[i]) == 'float64') | (str(df.dtypes[i]) == 'float32'):\n",
    "        formula_ml = formula_ml + ' + ' + df.columns[i]\n",
    "        \n",
    "# import the machine learning library that holds the randomforest\n",
    "import sklearn.ensemble as ske\n",
    "\n",
    "# Create the random forest model and fit the model to our training data\n",
    "y, x = dmatrices(formula_ml, data=df, return_type='dataframe')\n",
    "# RandomForestClassifier expects a 1 demensional NumPy array, so we convert\n",
    "y = np.asarray(y).ravel()\n",
    "\n",
    "# For prototype build, only use a tiny portion to test to save time\n",
    "testet = int(x.shape[0] * 0.05)\n",
    "x,y =  x[:testet], y[:testet]\n",
    "\n",
    "## Split data for testing and training\n",
    "offset = int(x.shape[0] * 0.75)\n",
    "X_train, y_train = x[:offset], y[:offset]\n",
    "X_test, y_test = x[offset:], y[offset:]\n",
    "\n",
    "#instantiate and fit our model\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "best_params = est.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# Try Support Vector Regression\n",
    "#failed as there are a lot string type predictors in Y\n",
    "param_grid = {'C': [100, 5, 10],\n",
    "              'kernel':('linear','rbf','poly'),\n",
    "              'epsilon': [1, 2, 5, 10],\n",
    "              'gamma': [10.0, 0.3, 0.1]\n",
    "              }\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# For prototype build, only use a tiny portion to test to save time\n",
    "\n",
    "X, y = shuffle(df.values, y, random_state=30)\n",
    "\n",
    "testet = int(X.shape[0] * 0.05)\n",
    "X,y =  X[:testet], y[:testet]\n",
    "\n",
    "## Split data for testing and training\n",
    "offset = int(X.shape[0] * 0.75)\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "                 \n",
    "svr = svm.SVR()\n",
    "clf = GridSearchCV(svm.SVR(),tuned_parameters, n_jobs=4, refit=True)\n",
    "#clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (clf.best_params_, clf.best_score_))\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "kernel = ('linear','rbf','poly')\n",
    "C_range = [0.000001,0.01,0.1,1,10,20,50]\n",
    "epsilon=  [0.00001,10,20,50,100]\n",
    "gamma_range = np.logspace(-99, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range, kernel = kernel,epsilon=epsilon)\n",
    "#cv = StratifiedShuffleSplit(y_train, n_iter=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "y = df.int_rate.values\n",
    "\n",
    "X, y = shuffle(df.values, y, random_state=30)\n",
    "\n",
    "clf = linear_model.SGDRegressor()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [  1.00000000e+00  -4.30332974e-18]\n",
      "Intercept:  -8.3848241435e-17\n",
      "P-Values:  [  0.00000000e+00   2.57519411e-15   8.17183010e-01   9.72282066e-01\n",
      "   0.00000000e+00   4.16335954e-03   4.59408667e-01   4.74378762e-12\n",
      "   7.97354651e-02   9.63592345e-01   7.74801798e-02   5.55669861e-01\n",
      "   3.63235517e-03   0.00000000e+00   4.58801081e-01   2.47003642e-03\n",
      "   5.99043520e-01   5.90999871e-01   2.88957834e-01   9.50901726e-03\n",
      "   4.83890809e-02   4.54312533e-01   7.44671971e-01   7.03684281e-01\n",
      "   5.78930145e-01   5.50063768e-02   1.15857144e-01   5.95404938e-03\n",
      "   4.48757626e-03   1.12243170e-01   3.15777347e-01   6.40378140e-01\n",
      "   7.79928398e-01   1.97570890e-01   1.79383394e-01   2.28003302e-02\n",
      "   3.05773056e-02   2.88877305e-01   3.47057342e-01   1.28821381e-01\n",
      "   9.92152059e-01   7.43828929e-01   3.93163208e-02   5.60534673e-01\n",
      "   4.03728969e-01   5.48214250e-01   1.27013170e-01   8.87022950e-02\n",
      "   4.27147049e-04   3.20480222e-01   2.34622602e-01   1.23395394e-02\n",
      "   6.74650375e-03   1.63021452e-01   1.93155862e-01   2.52348176e-01\n",
      "   5.33670316e-01   0.00000000e+00   7.46153868e-02   8.77651020e-01\n",
      "   7.67608674e-01   1.09635143e-01   2.71518688e-03   7.98660124e-03\n",
      "   1.08538549e-02   9.04460560e-04   4.04367411e-01   5.24795912e-01\n",
      "   2.69046813e-01   8.06518848e-01   8.81281251e-01   9.26535214e-02\n",
      "   5.23043035e-01   7.26396738e-01   2.09269220e-01   8.61574548e-03\n",
      "   2.59710774e-01   4.86608858e-01   2.88683498e-01   1.71245707e-01\n",
      "   8.09830433e-01   6.55360731e-01   7.15515109e-01   3.90348217e-01\n",
      "   6.85078594e-02   8.15963074e-01   4.04154393e-01   8.02679600e-01\n",
      "   4.12012551e-01   2.78201161e-01   1.36357063e-02   7.17403426e-01\n",
      "   9.23050955e-01   6.45721677e-01   7.20920965e-01   1.32821837e-01\n",
      "   7.45097874e-01   3.16535325e-01   6.87822023e-01   1.02939300e-01\n",
      "   9.16706971e-01   2.42607810e-01   8.35866073e-01   4.71032768e-01\n",
      "   3.90291999e-01   7.42113868e-01   5.31504706e-01   6.75677723e-01\n",
      "   6.10168673e-01   1.22431269e-01   5.80243996e-01   5.90517525e-01\n",
      "   8.81149417e-02   1.20762643e-03   3.27328034e-02   4.62805288e-01\n",
      "   1.78642090e-01   1.73851454e-01   4.68786166e-01   9.07585079e-01\n",
      "   5.13227402e-01   1.92165213e-01   5.31676586e-01   8.37969119e-01\n",
      "   9.42783264e-01   8.58136834e-01   2.99345976e-01   9.74702780e-01\n",
      "   7.45995644e-01   9.77155009e-01   5.03322884e-04   1.68301868e-02]\n",
      "R-Squared:  1.0\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y,X)\n",
    "f = model.fit()\n",
    "\n",
    "print ('Coefficients: ', f.params[0:2])\n",
    "print ('Intercept: ', f.params[2])\n",
    "print ('P-Values: ', f.pvalues)\n",
    "print ('R-Squared: ', f.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1299,  0.1449,  0.1398, ...,  0.1531,  0.1499,  0.1212])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1299,  0.1449,  0.1398, ...,  0.1531,  0.1499,  0.1212])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# # Set the parameters by cross-validation\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# scores = ['precision', 'recall']\n",
    "\n",
    "# for score in scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     print()\n",
    "\n",
    "#     clf = GridSearchCV(SVR(C=1), tuned_parameters, cv=5,\n",
    "#                        scoring='%s_weighted' % score)\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print()\n",
    "#     print(clf.best_params_)\n",
    "#     print()\n",
    "#     print(\"Grid scores on development set:\")\n",
    "#     print()\n",
    "#     for params, mean_score, scores in clf.grid_scores_:\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#               % (mean_score, scores.std() * 2, params))\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Create an acceptable formula for our machine learning algorithms\n",
    "# formula_ml = 'int_rate ~ C(grade) + C(subgrade) + annual_inc + dti + term + C(state)'\n",
    "# # import the machine learning library that holds the randomforest\n",
    "# import sklearn.ensemble as ske\n",
    "\n",
    "# # Create the random forest model and fit the model to our training data\n",
    "# y, x = dmatrices(formula_ml, data=df, return_type='dataframe')\n",
    "# # RandomForestClassifier expects a 1 demensional NumPy array, so we convert\n",
    "# y = np.asarray(y).ravel()\n",
    "# #instantiate and fit our model\n",
    "# results_rf = ske.RandomForestClassifier(n_estimators=100).fit(x, y)\n",
    "\n",
    "# # Score the results\n",
    "# score = results_rf.score(x, y)\n",
    "# print (\"Mean accuracy of Random Forest Predictions on the data was: {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_rate                  float64\n",
       "loan_amt                    int32\n",
       "term                        int32\n",
       "grade                      object\n",
       "subgrade                   object\n",
       "emp_length                  int32\n",
       "home_ownership             object\n",
       "annual_inc                float64\n",
       "verification_status        object\n",
       "issue_d                   float64\n",
       "loan_cat                   object\n",
       "state                      object\n",
       "dti                       float64\n",
       "delinq_2yrs               float64\n",
       "earliest_cr_line          float64\n",
       "inq_last_6mths            float64\n",
       "mths_since_last_record    float64\n",
       "num_opencr_line           float64\n",
       "num_der_rec               float64\n",
       "revol_bal                 float64\n",
       "revol_util                float64\n",
       "init_list_status           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df.dtypes[1]) == 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an acceptable formula for our machine learning algorithms\n",
    "#formula_ml = 'int_rate ~ C(grade) + loan_amt + C(subgrade) + annual_inc + dti + mths_since_last_record + C(state)'\n",
    "formula_ml = 'int_rate ~ loan_amt '\n",
    "for i in range(2,len(df.columns)):\n",
    "    \n",
    "    if str(df.dtypes[i]) == 'object': \n",
    "        formula = formula + ' + ' + 'C(' + df.columns[i] + ')'\n",
    "    elif (str(df.dtypes[i]) == 'float64') | (str(df.dtypes[i]) == 'float32'):\n",
    "        formula = formula + ' + ' + df.columns[i]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int_rate ~ loan_amt  + C(grade) + C(subgrade) + C(home_ownership) + annual_inc + C(verification_status) + issue_d + C(loan_cat) + C(state) + dti + delinq_2yrs + earliest_cr_line + inq_last_6mths + mths_since_last_record + num_opencr_line + num_der_rec + revol_bal + revol_util + C(init_list_status)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
